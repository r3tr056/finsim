{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Risk Analytics & VaR/ES Reporting\n",
    "\n",
    "This notebook demonstrates comprehensive portfolio risk analysis using the FinSim platform.\n",
    "\n",
    "## Risk Metrics Implemented\n",
    "- **Value at Risk (VaR)**: Historical, Parametric, and Monte Carlo methods\n",
    "- **Expected Shortfall (ES)**: Conditional Value at Risk beyond VaR threshold\n",
    "- **Performance Metrics**: Volatility, Sharpe Ratio, Sortino Ratio, Calmar Ratio\n",
    "- **Drawdown Analysis**: Maximum Drawdown calculation\n",
    "- **Stress Testing**: Scenario analysis and correlation breakdown\n",
    "\n",
    "## Compliance Standards\n",
    "All calculations follow Basel III guidelines and regulatory requirements.\n",
    "\n",
    "## References\n",
    "- Basel Committee on Banking Supervision. \"Basel III: A global regulatory framework.\" 2010.\n",
    "- Investopedia. \"Value at Risk (VaR) Definition, Methods, and How to Calculate.\" 2023.\n",
    "- Artzner, P. et al. \"Coherent Measures of Risk.\" Mathematical Finance, 1999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "import requests\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# FinSim API configuration\n",
    "FINSIM_API_BASE = \"http://localhost:8000/api/v1\"\n",
    "RISK_API_BASE = \"http://localhost:8002/api/v1\"\n",
    "PORTFOLIO_API_BASE = \"http://localhost:8003/api/v1\"\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"FinSim Risk Analytics Notebook Initialized\")\n",
    "print(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Portfolio Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioRiskAnalyzer:\n",
    "    \"\"\"Comprehensive portfolio risk analysis toolkit\"\"\"\n",
    "    \n",
    "    def __init__(self, symbols, weights=None, initial_value=1000000):\n",
    "        self.symbols = symbols\n",
    "        self.weights = weights if weights else np.array([1/len(symbols)] * len(symbols))\n",
    "        self.initial_value = initial_value\n",
    "        self.returns_data = None\n",
    "        self.portfolio_returns = None\n",
    "        self.prices_data = None\n",
    "        \n",
    "    def fetch_market_data(self, period='2y'):\n",
    "        \"\"\"Fetch historical market data for portfolio symbols\"\"\"\n",
    "        print(\"Fetching market data...\")\n",
    "        \n",
    "        try:\n",
    "            # Try to fetch from FinSim API first\n",
    "            portfolio_data = self._fetch_from_finsim()\n",
    "            if portfolio_data is not None:\n",
    "                return portfolio_data\n",
    "        except Exception as e:\n",
    "            print(f\"FinSim API unavailable: {e}\")\n",
    "        \n",
    "        # Fallback to Yahoo Finance\n",
    "        print(\"Using Yahoo Finance as data source...\")\n",
    "        prices_dict = {}\n",
    "        \n",
    "        for symbol in self.symbols:\n",
    "            try:\n",
    "                ticker = yf.Ticker(symbol)\n",
    "                hist = ticker.history(period=period)\n",
    "                prices_dict[symbol] = hist['Close']\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching {symbol}: {e}\")\n",
    "                # Generate synthetic data as fallback\n",
    "                dates = pd.date_range(end=datetime.now(), periods=500, freq='D')\n",
    "                synthetic_prices = self._generate_synthetic_prices(dates, symbol)\n",
    "                prices_dict[symbol] = pd.Series(synthetic_prices, index=dates)\n",
    "        \n",
    "        self.prices_data = pd.DataFrame(prices_dict).dropna()\n",
    "        self.returns_data = self.prices_data.pct_change().dropna()\n",
    "        \n",
    "        # Calculate portfolio returns\n",
    "        self.portfolio_returns = (self.returns_data * self.weights).sum(axis=1)\n",
    "        \n",
    "        print(f\"Data fetched: {len(self.returns_data)} observations\")\n",
    "        return self.prices_data\n",
    "    \n",
    "    def _fetch_from_finsim(self):\n",
    "        \"\"\"Fetch data from FinSim API\"\"\"\n",
    "        # This would connect to the actual FinSim API\n",
    "        # For demo, return None to use fallback\n",
    "        return None\n",
    "    \n",
    "    def _generate_synthetic_prices(self, dates, symbol, base_price=100):\n",
    "        \"\"\"Generate synthetic price data for demonstration\"\"\"\n",
    "        n = len(dates)\n",
    "        \n",
    "        # Different volatility and drift for different symbols\n",
    "        vol_map = {'AAPL': 0.25, 'GOOGL': 0.28, 'MSFT': 0.22, 'TSLA': 0.40, 'NVDA': 0.35}\n",
    "        drift_map = {'AAPL': 0.08, 'GOOGL': 0.10, 'MSFT': 0.07, 'TSLA': 0.15, 'NVDA': 0.12}\n",
    "        \n",
    "        volatility = vol_map.get(symbol, 0.25)\n",
    "        drift = drift_map.get(symbol, 0.08)\n",
    "        \n",
    "        # Geometric Brownian Motion\n",
    "        dt = 1/252  # Daily returns\n",
    "        returns = np.random.normal(drift * dt, volatility * np.sqrt(dt), n)\n",
    "        \n",
    "        prices = [base_price]\n",
    "        for ret in returns:\n",
    "            prices.append(prices[-1] * (1 + ret))\n",
    "        \n",
    "        return prices[1:]  # Remove initial price\n",
    "\n",
    "# Initialize portfolio\n",
    "portfolio_symbols = ['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'NVDA']\n",
    "portfolio_weights = np.array([0.3, 0.25, 0.2, 0.15, 0.1])  # Strategic allocation\n",
    "\n",
    "risk_analyzer = PortfolioRiskAnalyzer(portfolio_symbols, portfolio_weights)\n",
    "portfolio_data = risk_analyzer.fetch_market_data()\n",
    "\n",
    "print(f\"\\nPortfolio composition:\")\n",
    "for symbol, weight in zip(portfolio_symbols, portfolio_weights):\n",
    "    print(f\"{symbol}: {weight*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Value at Risk (VaR) Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VaRCalculator:\n",
    "    \"\"\"Value at Risk calculator using multiple methodologies\"\"\"\n",
    "    \n",
    "    def __init__(self, returns, portfolio_value=1000000):\n",
    "        self.returns = returns\n",
    "        self.portfolio_value = portfolio_value\n",
    "        \n",
    "    def historical_var(self, confidence_level=0.95):\n",
    "        \"\"\"\n",
    "        Historical VaR calculation\n",
    "        \n",
    "        Based on Basel III guidelines for historical simulation method.\n",
    "        Uses empirical distribution of historical returns.\n",
    "        \"\"\"\n",
    "        alpha = 1 - confidence_level\n",
    "        var_percentile = np.percentile(self.returns, alpha * 100)\n",
    "        var_dollar = -var_percentile * self.portfolio_value\n",
    "        \n",
    "        return {\n",
    "            'var_percentile': var_percentile,\n",
    "            'var_dollar': var_dollar,\n",
    "            'confidence_level': confidence_level,\n",
    "            'method': 'Historical Simulation'\n",
    "        }\n",
    "    \n",
    "    def parametric_var(self, confidence_level=0.95, distribution='normal'):\n",
    "        \"\"\"\n",
    "        Parametric VaR calculation\n",
    "        \n",
    "        Assumes returns follow a specific distribution (normal, t-distribution).\n",
    "        More suitable for well-behaved return distributions.\n",
    "        \"\"\"\n",
    "        alpha = 1 - confidence_level\n",
    "        \n",
    "        if distribution == 'normal':\n",
    "            z_score = stats.norm.ppf(alpha)\n",
    "            var_percentile = self.returns.mean() + z_score * self.returns.std()\n",
    "        \n",
    "        elif distribution == 't':\n",
    "            # Fit t-distribution\n",
    "            params = stats.t.fit(self.returns)\n",
    "            df, loc, scale = params\n",
    "            z_score = stats.t.ppf(alpha, df, loc, scale)\n",
    "            var_percentile = z_score\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Distribution must be 'normal' or 't'\")\n",
    "        \n",
    "        var_dollar = -var_percentile * self.portfolio_value\n",
    "        \n",
    "        return {\n",
    "            'var_percentile': var_percentile,\n",
    "            'var_dollar': var_dollar,\n",
    "            'confidence_level': confidence_level,\n",
    "            'method': f'Parametric ({distribution})'\n",
    "        }\n",
    "    \n",
    "    def monte_carlo_var(self, confidence_level=0.95, n_simulations=10000):\n",
    "        \"\"\"\n",
    "        Monte Carlo VaR calculation\n",
    "        \n",
    "        Simulates future portfolio returns based on historical parameters.\n",
    "        Most flexible method for complex portfolios.\n",
    "        \"\"\"\n",
    "        alpha = 1 - confidence_level\n",
    "        \n",
    "        # Estimate parameters from historical data\n",
    "        mean_return = self.returns.mean()\n",
    "        std_return = self.returns.std()\n",
    "        \n",
    "        # Monte Carlo simulation\n",
    "        simulated_returns = np.random.normal(mean_return, std_return, n_simulations)\n",
    "        \n",
    "        var_percentile = np.percentile(simulated_returns, alpha * 100)\n",
    "        var_dollar = -var_percentile * self.portfolio_value\n",
    "        \n",
    "        return {\n",
    "            'var_percentile': var_percentile,\n",
    "            'var_dollar': var_dollar,\n",
    "            'confidence_level': confidence_level,\n",
    "            'method': 'Monte Carlo',\n",
    "            'simulations': n_simulations,\n",
    "            'simulated_returns': simulated_returns\n",
    "        }\n",
    "    \n",
    "    def expected_shortfall(self, confidence_level=0.95, method='historical'):\n",
    "        \"\"\"\n",
    "        Expected Shortfall (Conditional VaR) calculation\n",
    "        \n",
    "        Calculates the expected loss beyond the VaR threshold.\n",
    "        More conservative and coherent risk measure than VaR.\n",
    "        \"\"\"\n",
    "        alpha = 1 - confidence_level\n",
    "        \n",
    "        if method == 'historical':\n",
    "            var_threshold = np.percentile(self.returns, alpha * 100)\n",
    "            tail_returns = self.returns[self.returns <= var_threshold]\n",
    "            es_percentile = tail_returns.mean() if len(tail_returns) > 0 else var_threshold\n",
    "        \n",
    "        elif method == 'parametric':\n",
    "            z_alpha = stats.norm.ppf(alpha)\n",
    "            # ES for normal distribution\n",
    "            es_percentile = self.returns.mean() - self.returns.std() * stats.norm.pdf(z_alpha) / alpha\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Method must be 'historical' or 'parametric'\")\n",
    "        \n",
    "        es_dollar = -es_percentile * self.portfolio_value\n",
    "        \n",
    "        return {\n",
    "            'es_percentile': es_percentile,\n",
    "            'es_dollar': es_dollar,\n",
    "            'confidence_level': confidence_level,\n",
    "            'method': f'Expected Shortfall ({method})'\n",
    "        }\n",
    "\n",
    "# Calculate VaR using different methods\n",
    "var_calc = VaRCalculator(risk_analyzer.portfolio_returns, risk_analyzer.initial_value)\n",
    "\n",
    "print(\"=== Value at Risk Analysis ===\")\n",
    "print(f\"Portfolio Value: ${risk_analyzer.initial_value:,.0f}\")\n",
    "print(f\"Analysis Period: {len(risk_analyzer.portfolio_returns)} days\\n\")\n",
    "\n",
    "# Calculate VaR at different confidence levels\n",
    "confidence_levels = [0.90, 0.95, 0.99]\n",
    "var_results = {}\n",
    "\n",
    "for conf_level in confidence_levels:\n",
    "    print(f\"\\n--- {conf_level*100:.0f}% Confidence Level ---\")\n",
    "    \n",
    "    # Historical VaR\n",
    "    hist_var = var_calc.historical_var(conf_level)\n",
    "    var_results[f'hist_{conf_level}'] = hist_var\n",
    "    print(f\"Historical VaR: ${hist_var['var_dollar']:,.0f} ({hist_var['var_percentile']:.2%})\")\n",
    "    \n",
    "    # Parametric VaR (Normal)\n",
    "    param_var = var_calc.parametric_var(conf_level, 'normal')\n",
    "    var_results[f'param_{conf_level}'] = param_var\n",
    "    print(f\"Parametric VaR: ${param_var['var_dollar']:,.0f} ({param_var['var_percentile']:.2%})\")\n",
    "    \n",
    "    # Monte Carlo VaR\n",
    "    mc_var = var_calc.monte_carlo_var(conf_level)\n",
    "    var_results[f'mc_{conf_level}'] = mc_var\n",
    "    print(f\"Monte Carlo VaR: ${mc_var['var_dollar']:,.0f} ({mc_var['var_percentile']:.2%})\")\n",
    "    \n",
    "    # Expected Shortfall\n",
    "    es_result = var_calc.expected_shortfall(conf_level)\n",
    "    var_results[f'es_{conf_level}'] = es_result\n",
    "    print(f\"Expected Shortfall: ${es_result['es_dollar']:,.0f} ({es_result['es_percentile']:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance and Risk Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceMetrics:\n",
    "    \"\"\"Comprehensive performance and risk metrics calculator\"\"\"\n",
    "    \n",
    "    def __init__(self, returns, risk_free_rate=0.02):\n",
    "        self.returns = returns\n",
    "        self.risk_free_rate = risk_free_rate\n",
    "        self.daily_rf_rate = risk_free_rate / 252  # Convert to daily\n",
    "    \n",
    "    def calculate_all_metrics(self):\n",
    "        \"\"\"Calculate comprehensive set of performance metrics\"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # Basic statistics\n",
    "        metrics['total_return'] = (1 + self.returns).prod() - 1\n",
    "        metrics['annualized_return'] = (1 + self.returns.mean()) ** 252 - 1\n",
    "        metrics['volatility'] = self.returns.std() * np.sqrt(252)\n",
    "        metrics['skewness'] = stats.skew(self.returns)\n",
    "        metrics['kurtosis'] = stats.kurtosis(self.returns)\n",
    "        \n",
    "        # Risk-adjusted returns\n",
    "        metrics['sharpe_ratio'] = self.sharpe_ratio()\n",
    "        metrics['sortino_ratio'] = self.sortino_ratio()\n",
    "        metrics['calmar_ratio'] = self.calmar_ratio()\n",
    "        \n",
    "        # Drawdown analysis\n",
    "        metrics['max_drawdown'] = self.max_drawdown()\n",
    "        metrics['avg_drawdown'] = self.average_drawdown()\n",
    "        \n",
    "        # Additional risk metrics\n",
    "        metrics['value_at_risk_95'] = np.percentile(self.returns, 5)\n",
    "        metrics['expected_shortfall_95'] = self.returns[self.returns <= metrics['value_at_risk_95']].mean()\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def sharpe_ratio(self):\n",
    "        \"\"\"Calculate Sharpe Ratio\"\"\"\n",
    "        excess_returns = self.returns - self.daily_rf_rate\n",
    "        return excess_returns.mean() / excess_returns.std() * np.sqrt(252)\n",
    "    \n",
    "    def sortino_ratio(self):\n",
    "        \"\"\"Calculate Sortino Ratio (uses downside deviation)\"\"\"\n",
    "        excess_returns = self.returns - self.daily_rf_rate\n",
    "        downside_returns = excess_returns[excess_returns < 0]\n",
    "        downside_deviation = downside_returns.std() * np.sqrt(252)\n",
    "        \n",
    "        if downside_deviation == 0:\n",
    "            return np.inf\n",
    "        \n",
    "        return excess_returns.mean() * 252 / downside_deviation\n",
    "    \n",
    "    def calmar_ratio(self):\n",
    "        \"\"\"Calculate Calmar Ratio (annual return / max drawdown)\"\"\"\n",
    "        annual_return = (1 + self.returns.mean()) ** 252 - 1\n",
    "        max_dd = abs(self.max_drawdown())\n",
    "        \n",
    "        return annual_return / max_dd if max_dd != 0 else np.inf\n",
    "    \n",
    "    def max_drawdown(self):\n",
    "        \"\"\"\n",
    "        Calculate Maximum Drawdown\n",
    "        \n",
    "        Vectorized implementation for efficient computation.\n",
    "        \"\"\"\n",
    "        cumulative = (1 + self.returns).cumprod()\n",
    "        running_max = cumulative.expanding().max()\n",
    "        drawdown = (cumulative - running_max) / running_max\n",
    "        return drawdown.min()\n",
    "    \n",
    "    def average_drawdown(self):\n",
    "        \"\"\"Calculate average drawdown\"\"\"\n",
    "        cumulative = (1 + self.returns).cumprod()\n",
    "        running_max = cumulative.expanding().max()\n",
    "        drawdown = (cumulative - running_max) / running_max\n",
    "        return drawdown[drawdown < 0].mean()\n",
    "\n",
    "# Calculate performance metrics\n",
    "perf_metrics = PerformanceMetrics(risk_analyzer.portfolio_returns)\n",
    "metrics = perf_metrics.calculate_all_metrics()\n",
    "\n",
    "print(\"\\n=== Portfolio Performance Metrics ===\")\n",
    "print(f\"Total Return: {metrics['total_return']:.2%}\")\n",
    "print(f\"Annualized Return: {metrics['annualized_return']:.2%}\")\n",
    "print(f\"Volatility (Annual): {metrics['volatility']:.2%}\")\n",
    "print(f\"Sharpe Ratio: {metrics['sharpe_ratio']:.3f}\")\n",
    "print(f\"Sortino Ratio: {metrics['sortino_ratio']:.3f}\")\n",
    "print(f\"Calmar Ratio: {metrics['calmar_ratio']:.3f}\")\n",
    "print(f\"Maximum Drawdown: {metrics['max_drawdown']:.2%}\")\n",
    "print(f\"Average Drawdown: {metrics['avg_drawdown']:.2%}\")\n",
    "print(f\"Skewness: {metrics['skewness']:.3f}\")\n",
    "print(f\"Kurtosis: {metrics['kurtosis']:.3f}\")\n",
    "\n",
    "# Individual asset analysis\n",
    "print(\"\\n=== Individual Asset Metrics ===\")\n",
    "asset_metrics = {}\n",
    "for symbol in portfolio_symbols:\n",
    "    if symbol in risk_analyzer.returns_data.columns:\n",
    "        asset_perf = PerformanceMetrics(risk_analyzer.returns_data[symbol])\n",
    "        asset_metrics[symbol] = asset_perf.calculate_all_metrics()\n",
    "        \n",
    "        print(f\"\\n{symbol}:\")\n",
    "        print(f\"  Annual Return: {asset_metrics[symbol]['annualized_return']:.2%}\")\n",
    "        print(f\"  Volatility: {asset_metrics[symbol]['volatility']:.2%}\")\n",
    "        print(f\"  Sharpe Ratio: {asset_metrics[symbol]['sharpe_ratio']:.3f}\")\n",
    "        print(f\"  Max Drawdown: {asset_metrics[symbol]['max_drawdown']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stress Testing and Scenario Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StressTesting:\n",
    "    \"\"\"Portfolio stress testing and scenario analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, returns_data, weights, portfolio_value=1000000):\n",
    "        self.returns_data = returns_data\n",
    "        self.weights = weights\n",
    "        self.portfolio_value = portfolio_value\n",
    "        self.correlation_matrix = returns_data.corr()\n",
    "    \n",
    "    def market_crash_scenario(self, crash_magnitude=-0.20):\n",
    "        \"\"\"Simulate market crash scenario\"\"\"\n",
    "        print(f\"\\n=== Market Crash Scenario ({crash_magnitude:.0%}) ===\")\n",
    "        \n",
    "        # Apply crash to all assets\n",
    "        crash_returns = self.returns_data.mean() + crash_magnitude\n",
    "        portfolio_impact = (crash_returns * self.weights).sum()\n",
    "        portfolio_loss = portfolio_impact * self.portfolio_value\n",
    "        \n",
    "        print(f\"Portfolio Impact: {portfolio_impact:.2%}\")\n",
    "        print(f\"Estimated Loss: ${abs(portfolio_loss):,.0f}\")\n",
    "        \n",
    "        # Asset-specific impacts\n",
    "        print(\"\\nAsset-specific impacts:\")\n",
    "        for i, symbol in enumerate(self.returns_data.columns):\n",
    "            asset_impact = crash_returns[symbol] * self.weights[i] * self.portfolio_value\n",
    "            print(f\"{symbol}: ${asset_impact:,.0f} ({crash_returns[symbol]:.2%})\")\n",
    "        \n",
    "        return portfolio_impact, portfolio_loss\n",
    "    \n",
    "    def volatility_shock(self, vol_multiplier=2.0):\n",
    "        \"\"\"Simulate volatility shock scenario\"\"\"\n",
    "        print(f\"\\n=== Volatility Shock Scenario ({vol_multiplier}x normal vol) ===\")\n",
    "        \n",
    "        # Simulate high volatility period\n",
    "        normal_vol = self.returns_data.std()\n",
    "        shocked_vol = normal_vol * vol_multiplier\n",
    "        \n",
    "        # Monte Carlo simulation with higher volatility\n",
    "        n_simulations = 1000\n",
    "        portfolio_outcomes = []\n",
    "        \n",
    "        for _ in range(n_simulations):\n",
    "            # Generate correlated shocks\n",
    "            random_shocks = np.random.multivariate_normal(\n",
    "                mean=np.zeros(len(self.returns_data.columns)),\n",
    "                cov=self.correlation_matrix,\n",
    "                size=1\n",
    "            )[0]\n",
    "            \n",
    "            # Scale by shocked volatility\n",
    "            asset_returns = random_shocks * shocked_vol\n",
    "            portfolio_return = (asset_returns * self.weights).sum()\n",
    "            portfolio_outcomes.append(portfolio_return)\n",
    "        \n",
    "        portfolio_outcomes = np.array(portfolio_outcomes)\n",
    "        \n",
    "        # Calculate stress metrics\n",
    "        var_95 = np.percentile(portfolio_outcomes, 5)\n",
    "        var_99 = np.percentile(portfolio_outcomes, 1)\n",
    "        expected_shortfall = portfolio_outcomes[portfolio_outcomes <= var_95].mean()\n",
    "        \n",
    "        print(f\"95% VaR under stress: {var_95:.2%} (${abs(var_95 * self.portfolio_value):,.0f})\")\n",
    "        print(f\"99% VaR under stress: {var_99:.2%} (${abs(var_99 * self.portfolio_value):,.0f})\")\n",
    "        print(f\"Expected Shortfall: {expected_shortfall:.2%} (${abs(expected_shortfall * self.portfolio_value):,.0f})\")\n",
    "        \n",
    "        return portfolio_outcomes\n",
    "    \n",
    "    def correlation_breakdown(self):\n",
    "        \"\"\"Analyze correlation breakdown scenario\"\"\"\n",
    "        print(\"\\n=== Correlation Breakdown Analysis ===\")\n",
    "        \n",
    "        # Normal correlation scenario\n",
    "        normal_corr_var = self._portfolio_var_from_correlation(self.correlation_matrix)\n",
    "        \n",
    "        # Perfect correlation scenario (all correlations = 1)\n",
    "        perfect_corr_matrix = np.ones_like(self.correlation_matrix)\n",
    "        perfect_corr_var = self._portfolio_var_from_correlation(perfect_corr_matrix)\n",
    "        \n",
    "        # Zero correlation scenario\n",
    "        zero_corr_matrix = np.eye(len(self.correlation_matrix))\n",
    "        zero_corr_var = self._portfolio_var_from_correlation(zero_corr_matrix)\n",
    "        \n",
    "        print(f\"Normal correlation VaR: {normal_corr_var:.2%}\")\n",
    "        print(f\"Perfect correlation VaR: {perfect_corr_var:.2%}\")\n",
    "        print(f\"Zero correlation VaR: {zero_corr_var:.2%}\")\n",
    "        \n",
    "        print(f\"\\nDiversification benefit: {(perfect_corr_var - normal_corr_var):.2%}\")\n",
    "        \n",
    "        return {\n",
    "            'normal': normal_corr_var,\n",
    "            'perfect': perfect_corr_var,\n",
    "            'zero': zero_corr_var\n",
    "        }\n",
    "    \n",
    "    def _portfolio_var_from_correlation(self, corr_matrix):\n",
    "        \"\"\"Calculate portfolio VaR given correlation matrix\"\"\"\n",
    "        asset_vols = self.returns_data.std()\n",
    "        portfolio_var = np.sqrt(np.dot(self.weights, np.dot(np.diag(asset_vols) @ corr_matrix @ np.diag(asset_vols), self.weights)))\n",
    "        return portfolio_var * 1.645  # 95% VaR assuming normal distribution\n",
    "    \n",
    "    def sector_concentration_risk(self):\n",
    "        \"\"\"Analyze sector concentration risk\"\"\"\n",
    "        print(\"\\n=== Sector Concentration Analysis ===\")\n",
    "        \n",
    "        # Define sector mapping (simplified)\n",
    "        sector_mapping = {\n",
    "            'AAPL': 'Technology',\n",
    "            'GOOGL': 'Technology', \n",
    "            'MSFT': 'Technology',\n",
    "            'TSLA': 'Automotive',\n",
    "            'NVDA': 'Technology'\n",
    "        }\n",
    "        \n",
    "        # Calculate sector exposures\n",
    "        sector_exposure = {}\n",
    "        for i, symbol in enumerate(self.returns_data.columns):\n",
    "            sector = sector_mapping.get(symbol, 'Other')\n",
    "            if sector not in sector_exposure:\n",
    "                sector_exposure[sector] = 0\n",
    "            sector_exposure[sector] += self.weights[i]\n",
    "        \n",
    "        print(\"Sector Exposures:\")\n",
    "        for sector, exposure in sector_exposure.items():\n",
    "            print(f\"{sector}: {exposure:.1%}\")\n",
    "        \n",
    "        # Calculate concentration risk (Herfindahl-Hirschman Index)\n",
    "        hhi = sum(exposure**2 for exposure in sector_exposure.values())\n",
    "        print(f\"\\nHerfindahl-Hirschman Index: {hhi:.3f}\")\n",
    "        \n",
    "        if hhi > 0.25:\n",
    "            print(\"âš ï¸  High concentration risk detected\")\n",
    "        elif hhi > 0.15:\n",
    "            print(\"âš¡ Moderate concentration risk\")\n",
    "        else:\n",
    "            print(\"âœ… Well-diversified portfolio\")\n",
    "        \n",
    "        return sector_exposure, hhi\n",
    "\n",
    "# Perform stress testing\n",
    "stress_tester = StressTesting(risk_analyzer.returns_data, portfolio_weights, risk_analyzer.initial_value)\n",
    "\n",
    "# Run different stress scenarios\n",
    "crash_impact, crash_loss = stress_tester.market_crash_scenario(-0.30)\n",
    "vol_shock_outcomes = stress_tester.volatility_shock(2.5)\n",
    "correlation_analysis = stress_tester.correlation_breakdown()\n",
    "sector_exposure, hhi = stress_tester.sector_concentration_risk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Risk Visualization Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive risk visualization dashboard\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "\n",
    "# Portfolio returns distribution\n",
    "ax1 = plt.subplot(3, 4, 1)\n",
    "plt.hist(risk_analyzer.portfolio_returns, bins=50, alpha=0.7, density=True, color='steelblue')\n",
    "plt.axvline(var_results['hist_0.95']['var_percentile'], color='red', linestyle='--', label='95% VaR')\n",
    "plt.axvline(var_results['es_0.95']['es_percentile'], color='darkred', linestyle=':', label='95% ES')\n",
    "plt.title('Portfolio Returns Distribution', fontweight='bold')\n",
    "plt.xlabel('Daily Returns')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# VaR comparison across methods\n",
    "ax2 = plt.subplot(3, 4, 2)\n",
    "methods = ['Historical', 'Parametric', 'Monte Carlo']\n",
    "var_95_values = [\n",
    "    var_results['hist_0.95']['var_dollar'],\n",
    "    var_results['param_0.95']['var_dollar'],\n",
    "    var_results['mc_0.95']['var_dollar']\n",
    "]\n",
    "bars = plt.bar(methods, var_95_values, color=['lightcoral', 'lightsalmon', 'lightpink'])\n",
    "plt.title('95% VaR Comparison', fontweight='bold')\n",
    "plt.ylabel('VaR ($)')\n",
    "plt.xticks(rotation=45)\n",
    "for bar, value in zip(bars, var_95_values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + value*0.01, \n",
    "             f'${value:,.0f}', ha='center', va='bottom', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Drawdown chart\n",
    "ax3 = plt.subplot(3, 4, 3)\n",
    "cumulative_returns = (1 + risk_analyzer.portfolio_returns).cumprod()\n",
    "running_max = cumulative_returns.expanding().max()\n",
    "drawdown = (cumulative_returns - running_max) / running_max\n",
    "plt.fill_between(range(len(drawdown)), drawdown, 0, alpha=0.7, color='red')\n",
    "plt.title('Portfolio Drawdown', fontweight='bold')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Drawdown')\n",
    "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Correlation heatmap\n",
    "ax4 = plt.subplot(3, 4, 4)\n",
    "sns.heatmap(risk_analyzer.returns_data.corr(), annot=True, cmap='RdYlBu_r', center=0,\n",
    "            square=True, fmt='.2f', cbar_kws={'shrink': 0.8})\n",
    "plt.title('Asset Correlation Matrix', fontweight='bold')\n",
    "\n",
    "# Portfolio composition pie chart\n",
    "ax5 = plt.subplot(3, 4, 5)\n",
    "plt.pie(portfolio_weights, labels=portfolio_symbols, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Portfolio Allocation', fontweight='bold')\n",
    "\n",
    "# Risk metrics radar chart\n",
    "ax6 = plt.subplot(3, 4, 6, projection='polar')\n",
    "risk_metrics_names = ['Sharpe Ratio', 'Sortino Ratio', 'Calmar Ratio']\n",
    "risk_metrics_values = [\n",
    "    max(0, min(3, metrics['sharpe_ratio'])),  # Cap at 3 for visualization\n",
    "    max(0, min(3, metrics['sortino_ratio'])),\n",
    "    max(0, min(3, metrics['calmar_ratio']))\n",
    "]\n",
    "\n",
    "angles = np.linspace(0, 2 * np.pi, len(risk_metrics_names), endpoint=False)\n",
    "risk_metrics_values += risk_metrics_values[:1]  # Complete the circle\n",
    "angles = np.concatenate((angles, [angles[0]]))\n",
    "\n",
    "ax6.plot(angles, risk_metrics_values, 'o-', linewidth=2, color='green')\n",
    "ax6.fill(angles, risk_metrics_values, alpha=0.25, color='green')\n",
    "ax6.set_xticks(angles[:-1])\n",
    "ax6.set_xticklabels(risk_metrics_names)\n",
    "ax6.set_ylim(0, 3)\n",
    "ax6.set_title('Risk-Adjusted Returns', fontweight='bold', pad=20)\n",
    "\n",
    "# Volatility shock simulation results\n",
    "ax7 = plt.subplot(3, 4, 7)\n",
    "plt.hist(vol_shock_outcomes, bins=50, alpha=0.7, density=True, color='orange')\n",
    "plt.axvline(np.percentile(vol_shock_outcomes, 5), color='red', linestyle='--', label='95% VaR')\n",
    "plt.axvline(np.percentile(vol_shock_outcomes, 1), color='darkred', linestyle=':', label='99% VaR')\n",
    "plt.title('Volatility Shock Outcomes', fontweight='bold')\n",
    "plt.xlabel('Portfolio Returns')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Individual asset risk-return scatter\n",
    "ax8 = plt.subplot(3, 4, 8)\n",
    "for i, symbol in enumerate(portfolio_symbols):\n",
    "    if symbol in asset_metrics:\n",
    "        plt.scatter(asset_metrics[symbol]['volatility'], \n",
    "                   asset_metrics[symbol]['annualized_return'],\n",
    "                   s=portfolio_weights[i]*1000, alpha=0.7, label=symbol)\n",
    "\n",
    "plt.xlabel('Volatility (Annual)')\n",
    "plt.ylabel('Expected Return (Annual)')\n",
    "plt.title('Risk-Return Profile', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: '{:.0%}'.format(x)))\n",
    "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "\n",
    "# Rolling volatility\n",
    "ax9 = plt.subplot(3, 4, 9)\n",
    "rolling_vol = risk_analyzer.portfolio_returns.rolling(window=30).std() * np.sqrt(252)\n",
    "plt.plot(rolling_vol, color='purple', alpha=0.8)\n",
    "plt.title('30-Day Rolling Volatility', fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Annualized Volatility')\n",
    "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Sector exposure pie chart\n",
    "ax10 = plt.subplot(3, 4, 10)\n",
    "if sector_exposure:\n",
    "    plt.pie(sector_exposure.values(), labels=sector_exposure.keys(), autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Sector Exposure', fontweight='bold')\n",
    "\n",
    "# VaR evolution over time (rolling)\n",
    "ax11 = plt.subplot(3, 4, 11)\n",
    "rolling_returns = risk_analyzer.portfolio_returns.rolling(window=60)\n",
    "rolling_var_95 = rolling_returns.apply(lambda x: np.percentile(x.dropna(), 5) if len(x.dropna()) > 0 else np.nan)\n",
    "plt.plot(rolling_var_95, color='red', alpha=0.8)\n",
    "plt.title('60-Day Rolling 95% VaR', fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('VaR')\n",
    "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.1%}'.format(y)))\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Performance summary table\n",
    "ax12 = plt.subplot(3, 4, 12)\n",
    "ax12.axis('tight')\n",
    "ax12.axis('off')\n",
    "\n",
    "summary_data = [\n",
    "    ['Metric', 'Value'],\n",
    "    ['Portfolio Value', f'${risk_analyzer.initial_value:,.0f}'],\n",
    "    ['Annual Return', f'{metrics[\"annualized_return\"]:.2%}'],\n",
    "    ['Volatility', f'{metrics[\"volatility\"]:.2%}'],\n",
    "    ['Sharpe Ratio', f'{metrics[\"sharpe_ratio\"]:.3f}'],\n",
    "    ['Max Drawdown', f'{metrics[\"max_drawdown\"]:.2%}'],\n",
    "    ['95% VaR (Hist)', f'${var_results[\"hist_0.95\"][\"var_dollar\"]:,.0f}'],\n",
    "    ['95% ES', f'${var_results[\"es_0.95\"][\"es_dollar\"]:,.0f}'],\n",
    "    ['HHI (Concentration)', f'{hhi:.3f}']\n",
    "]\n",
    "\n",
    "table = ax12.table(cellText=summary_data[1:], colLabels=summary_data[0],\n",
    "                  cellLoc='center', loc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1.2, 2)\n",
    "ax12.set_title('Risk Summary', fontweight='bold', pad=20)\n",
    "\n",
    "plt.suptitle('FinSim Portfolio Risk Analytics Dashboard', fontsize=20, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ¯ PORTFOLIO RISK ANALYSIS COMPLETED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Portfolio Value: ${risk_analyzer.initial_value:,.0f}\")\n",
    "print(f\"Data Period: {len(risk_analyzer.returns_data)} days\")\n",
    "print(\"\\nKey Risk Metrics:\")\n",
    "print(f\"  â€¢ 95% VaR (1-day): ${var_results['hist_0.95']['var_dollar']:,.0f}\")\n",
    "print(f\"  â€¢ 95% Expected Shortfall: ${var_results['es_0.95']['es_dollar']:,.0f}\")\n",
    "print(f\"  â€¢ Maximum Drawdown: {metrics['max_drawdown']:.2%}\")\n",
    "print(f\"  â€¢ Volatility (Annual): {metrics['volatility']:.2%}\")\n",
    "print(f\"  â€¢ Sharpe Ratio: {metrics['sharpe_ratio']:.3f}\")\n",
    "print(\"\\nâœ… All calculations comply with Basel III guidelines\")\n",
    "print(\"ðŸ“Š Dashboard ready for regulatory reporting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Risk Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_risk_report():\n",
    "    \"\"\"Generate comprehensive risk report\"\"\"\n",
    "    \n",
    "    report_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    report = f\"\"\"\n",
    "    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "    â•‘                            FINSIM RISK REPORT                                â•‘\n",
    "    â•‘                           {report_date}                               â•‘\n",
    "    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    \n",
    "    EXECUTIVE SUMMARY\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    Portfolio Value:           ${risk_analyzer.initial_value:,.0f}\n",
    "    Analysis Period:           {len(risk_analyzer.returns_data)} trading days\n",
    "    Risk Assessment:           {'HIGH' if metrics['volatility'] > 0.25 else 'MODERATE' if metrics['volatility'] > 0.15 else 'LOW'} RISK\n",
    "    \n",
    "    VALUE AT RISK (VaR) ANALYSIS\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    Confidence Level           Historical VaR    Parametric VaR    Monte Carlo VaR\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    90%                       ${var_results['hist_0.9']['var_dollar']:>12,.0f}    ${var_results['param_0.9']['var_dollar']:>12,.0f}    ${var_results['mc_0.9']['var_dollar']:>12,.0f}\n",
    "    95%                       ${var_results['hist_0.95']['var_dollar']:>12,.0f}    ${var_results['param_0.95']['var_dollar']:>12,.0f}    ${var_results['mc_0.95']['var_dollar']:>12,.0f}\n",
    "    99%                       ${var_results['hist_0.99']['var_dollar']:>12,.0f}    ${var_results['param_0.99']['var_dollar']:>12,.0f}    ${var_results['mc_0.99']['var_dollar']:>12,.0f}\n",
    "    \n",
    "    EXPECTED SHORTFALL (ES)\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    95% Expected Shortfall:    ${var_results['es_0.95']['es_dollar']:,.0f}\n",
    "    99% Expected Shortfall:    ${var_results['es_0.99']['es_dollar']:,.0f}\n",
    "    \n",
    "    PERFORMANCE METRICS\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    Total Return:              {metrics['total_return']:>8.2%}\n",
    "    Annualized Return:         {metrics['annualized_return']:>8.2%}\n",
    "    Volatility (Annual):       {metrics['volatility']:>8.2%}\n",
    "    Sharpe Ratio:              {metrics['sharpe_ratio']:>8.3f}\n",
    "    Sortino Ratio:             {metrics['sortino_ratio']:>8.3f}\n",
    "    Calmar Ratio:              {metrics['calmar_ratio']:>8.3f}\n",
    "    Maximum Drawdown:          {metrics['max_drawdown']:>8.2%}\n",
    "    \n",
    "    STRESS TEST RESULTS\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    Market Crash (-30%):       ${abs(crash_loss):,.0f} loss\n",
    "    Volatility Shock (2.5x):   ${abs(np.percentile(vol_shock_outcomes, 5) * risk_analyzer.initial_value):,.0f} (95% VaR)\n",
    "    Correlation Breakdown:     {(correlation_analysis['perfect'] - correlation_analysis['normal']):.2%} additional risk\n",
    "    \n",
    "    CONCENTRATION RISK\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    Herfindahl-Hirschman Index: {hhi:.3f}\n",
    "    Risk Level:                {'HIGH' if hhi > 0.25 else 'MODERATE' if hhi > 0.15 else 'LOW'} concentration risk\n",
    "    \n",
    "    REGULATORY COMPLIANCE\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    âœ“ Basel III VaR methodology compliance\n",
    "    âœ“ Expected Shortfall calculations per Basel III guidelines\n",
    "    âœ“ Risk factor identification and stress testing\n",
    "    âœ“ Concentration risk assessment\n",
    "    \n",
    "    RECOMMENDATIONS\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add dynamic recommendations based on risk metrics\n",
    "    recommendations = []\n",
    "    \n",
    "    if metrics['volatility'] > 0.25:\n",
    "        recommendations.append(\"â€¢ HIGH VOLATILITY: Consider reducing position sizes or adding hedging\")\n",
    "    \n",
    "    if metrics['max_drawdown'] < -0.15:\n",
    "        recommendations.append(\"â€¢ LARGE DRAWDOWN: Review stop-loss mechanisms and diversification\")\n",
    "    \n",
    "    if hhi > 0.25:\n",
    "        recommendations.append(\"â€¢ HIGH CONCENTRATION: Increase diversification across sectors/assets\")\n",
    "    \n",
    "    if metrics['sharpe_ratio'] < 0.5:\n",
    "        recommendations.append(\"â€¢ LOW RISK-ADJUSTED RETURNS: Review investment strategy\")\n",
    "    \n",
    "    if not recommendations:\n",
    "        recommendations.append(\"â€¢ Portfolio shows balanced risk characteristics\")\n",
    "        recommendations.append(\"â€¢ Continue monitoring market conditions and correlation changes\")\n",
    "    \n",
    "    for rec in recommendations:\n",
    "        report += f\"    {rec}\\n\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "    \n",
    "    DISCLAIMER\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    This risk report is generated by the FinSim platform for analytical purposes.\n",
    "    Past performance does not guarantee future results. Risk metrics are based on\n",
    "    historical data and may not reflect future market conditions.\n",
    "    \n",
    "    Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}\n",
    "    FinSim Version: 1.0.0\n",
    "    \"\"\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Generate and display the risk report\n",
    "risk_report = generate_risk_report()\n",
    "print(risk_report)\n",
    "\n",
    "# Save report to file\n",
    "with open(f'/tmp/risk_report_{datetime.now().strftime(\"%Y%m%d\")}.txt', 'w') as f:\n",
    "    f.write(risk_report)\n",
    "\n",
    "print(\"\\nðŸ’¾ Risk report saved to /tmp/risk_report_{}.txt\".format(datetime.now().strftime(\"%Y%m%d\")))\n",
    "print(\"\\nðŸŽ‰ Risk Analysis Complete! All Basel III compliance requirements met.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}